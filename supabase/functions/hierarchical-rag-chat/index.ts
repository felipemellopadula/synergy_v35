import "https://deno.land/x/xhr@0.3.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

// ============= CONFIGURAÃ‡Ã•ES =============
const ACTIVATION_THRESHOLD_PAGES = 20;
const TARGET_OUTPUT_RATIO = 0.7; // 70% do original
const CHUNK_OUTPUT_RATIO = 0.9;  // NÃ­vel 1: 90%
const SECTION_OUTPUT_RATIO = 0.8; // NÃ­vel 2: 80%
const FINAL_OUTPUT_RATIO = 0.93; // NÃ­vel 3: 93% (para atingir 70% total)

const TOKENS_PER_PAGE = 1400;
const CHARS_PER_PAGE = 3500;

// ConfiguraÃ§Ãµes de chunking adaptativo
const getChunkConfig = (pages: number) => {
  if (pages <= 50) return { chunkPages: 12, overlapPages: 2 };
  if (pages <= 100) return { chunkPages: 15, overlapPages: 3 };
  if (pages <= 200) return { chunkPages: 20, overlapPages: 4 };
  if (pages <= 500) return { chunkPages: 25, overlapPages: 5 };
  if (pages <= 1000) return { chunkPages: 30, overlapPages: 6 };
  return { chunkPages: 40, overlapPages: 8 };
};

// EstimaÃ§Ã£o de tokens
const estimateTokens = (text: string): number => Math.ceil(text.length / 4);

// Delay helper
const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

// ============= NÃVEL 0: CHUNKING INTELIGENTE =============
const createAdaptiveChunks = (content: string, totalPages: number): string[] => {
  const { chunkPages, overlapPages } = getChunkConfig(totalPages);
  const chunkSize = chunkPages * CHARS_PER_PAGE;
  const overlapSize = overlapPages * CHARS_PER_PAGE;
  
  const chunks: string[] = [];
  let position = 0;
  
  while (position < content.length) {
    const end = Math.min(position + chunkSize, content.length);
    chunks.push(content.slice(position, end));
    position += (chunkSize - overlapSize);
    
    if (end === content.length) break;
  }
  
  console.log(`ğŸ“š Criados ${chunks.length} chunks (${chunkPages} pÃ¡ginas cada, overlap ${overlapPages} pÃ¡ginas)`);
  return chunks;
};

// ============= NÃVEL 1: CHUNK ANALYSIS =============
const analyzeChunk = async (
  chunk: string,
  chunkIndex: number,
  totalChunks: number,
  totalPages: number,
  openAIApiKey: string,
  retryCount = 0
): Promise<string> => {
  const chunkTokens = estimateTokens(chunk);
  const chunkPages = Math.ceil(chunkTokens / TOKENS_PER_PAGE);
  const targetOutputTokens = Math.floor(chunkTokens * CHUNK_OUTPUT_RATIO);
  
  console.log(`ğŸ” Chunk ${chunkIndex + 1}/${totalChunks}: ${chunkPages} pÃ¡ginas â†’ ${Math.floor(chunkPages * CHUNK_OUTPUT_RATIO)} pÃ¡ginas`);
  
  const prompt = `VocÃª Ã© um analista especializado em PRESERVAÃ‡ÃƒO MÃXIMA DE INFORMAÃ‡ÃƒO.

ğŸ“„ CHUNK [${chunkIndex + 1} de ${totalChunks}] de um documento de ${totalPages} pÃ¡ginas

${chunk}

ğŸ¯ MISSÃƒO: Crie uma anÃ¡lise ULTRA-DETALHADA de ${targetOutputTokens} tokens (90% do original) que preserve:

1. ğŸ“‹ ESTRUTURA COMPLETA
   - Todos os tÃ­tulos, subtÃ­tulos e hierarquia
   - NumeraÃ§Ã£o de seÃ§Ãµes e referÃªncias
   - OrganizaÃ§Ã£o lÃ³gica do conteÃºdo

2. ğŸ’ CONTEÃšDO ESSENCIAL (MÃXIMA PRESERVAÃ‡ÃƒO)
   - Todos os conceitos principais explicados em detalhes
   - Argumentos centrais com contexto completo
   - DefiniÃ§Ãµes e terminologias importantes
   - Exemplos relevantes e casos prÃ¡ticos

3. ğŸ“Š DADOS CRÃTICOS (100% DE RETENÃ‡ÃƒO)
   - Todas as tabelas, grÃ¡ficos e estatÃ­sticas
   - NÃºmeros, percentuais e mÃ©tricas exatas
   - CitaÃ§Ãµes textuais relevantes
   - ReferÃªncias bibliogrÃ¡ficas e fontes

4. ğŸ”— CONEXÃ•ES E RELAÃ‡Ã•ES
   - ReferÃªncias a outras seÃ§Ãµes do documento
   - LigaÃ§Ãµes conceituais entre tÃ³picos
   - DependÃªncias e prÃ©-requisitos

5. ğŸ§  INSIGHTS E ANÃLISE
   - Pontos de destaque e descobertas
   - ImplicaÃ§Ãµes e consequÃªncias
   - QuestÃµes emergentes

âš ï¸ REGRAS CRÃTICAS:
- NÃƒO resuma excessivamente - mantenha riqueza de detalhes
- NÃƒO descarte informaÃ§Ãµes secundÃ¡rias
- MANTENHA o nÃ­vel tÃ©cnico original
- USE Markdown (H2/H3/H4, listas, tabelas)
- PRESERVE citaÃ§Ãµes literais

ğŸ¯ Target: ${targetOutputTokens} tokens (â‰ˆ${Math.floor(chunkPages * CHUNK_OUTPUT_RATIO)} pÃ¡ginas)`;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${openAIApiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-4.1-2025-04-14",
        messages: [{ role: "user", content: prompt }],
        max_completion_tokens: Math.min(64000, targetOutputTokens),
        temperature: 0.3,
        stream: false,
      }),
    });

    if (response.status === 429 && retryCount < 3) {
      console.log(`â³ Rate limit hit, retrying chunk ${chunkIndex + 1} in 60s (attempt ${retryCount + 1}/3)`);
      await delay(60000);
      return analyzeChunk(chunk, chunkIndex, totalChunks, totalPages, openAIApiKey, retryCount + 1);
    }

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Chunk analysis failed: ${response.status} - ${errorText}`);
    }
    
    const data = await response.json();
    const result = data.choices[0].message.content;
    
    console.log(`âœ… Chunk ${chunkIndex + 1}: ${estimateTokens(result)} tokens gerados`);
    return result;
  } catch (error) {
    console.error(`âŒ Error analyzing chunk ${chunkIndex + 1}:`, error);
    throw error;
  }
};

// ============= NÃVEL 2: SECTION SYNTHESIS =============
const synthesizeSection = async (
  chunkAnalyses: string[],
  sectionIndex: number,
  totalSections: number,
  openAIApiKey: string,
  retryCount = 0
): Promise<string> => {
  const totalSectionTokens = chunkAnalyses.reduce((sum, analysis) => sum + estimateTokens(analysis), 0);
  const targetOutputTokens = Math.floor(totalSectionTokens * SECTION_OUTPUT_RATIO);
  const totalSectionPages = Math.ceil(totalSectionTokens / TOKENS_PER_PAGE);
  
  console.log(`ğŸ§© Section ${sectionIndex + 1}/${totalSections}: ${chunkAnalyses.length} chunks (${totalSectionPages} pÃ¡ginas) â†’ ${Math.floor(totalSectionPages * SECTION_OUTPUT_RATIO)} pÃ¡ginas`);
  
  const prompt = `VocÃª Ã© um sintetizador especializado em CONSOLIDAÃ‡ÃƒO SEM PERDA.

ğŸ“š SEÃ‡ÃƒO [${sectionIndex + 1} de ${totalSections}] - Consolidando ${chunkAnalyses.length} chunks

ANÃLISES DOS CHUNKS:
${chunkAnalyses.map((analysis, i) => `\n[CHUNK ${i+1}/${chunkAnalyses.length}]\n${analysis}\n`).join('\n---\n')}

ğŸ¯ MISSÃƒO: Crie uma SÃNTESE CONSOLIDADA de ${targetOutputTokens} tokens (80% do agregado) que:

1. ğŸ”— INTEGRE todos os chunks mantendo estrutura hierÃ¡rquica e fluxo lÃ³gico
2. ğŸ’ PRESERVE conceitos, argumentos, dados, tabelas e exemplos
3. ğŸ§© ELIMINE apenas redundÃ¢ncias e repetiÃ§Ãµes entre chunks
4. âœ¨ ADICIONE conexÃµes identificadas entre chunks e padrÃµes recorrentes

âš ï¸ REGRAS:
- MÃ¡xima fidelidade ao original
- NÃƒO crie conteÃºdo novo
- PRESERVE dados numÃ©ricos e citaÃ§Ãµes
- USE Markdown estruturado

ğŸ¯ Target: ${targetOutputTokens} tokens (â‰ˆ${Math.floor(totalSectionPages * SECTION_OUTPUT_RATIO)} pÃ¡ginas)`;

  try {
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${openAIApiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-4.1-2025-04-14",
        messages: [{ role: "user", content: prompt }],
        max_completion_tokens: Math.min(64000, targetOutputTokens),
        temperature: 0.2,
        stream: false,
      }),
    });

    if (response.status === 429 && retryCount < 3) {
      console.log(`â³ Rate limit hit, retrying section ${sectionIndex + 1} in 60s (attempt ${retryCount + 1}/3)`);
      await delay(60000);
      return synthesizeSection(chunkAnalyses, sectionIndex, totalSections, openAIApiKey, retryCount + 1);
    }

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Section synthesis failed: ${response.status} - ${errorText}`);
    }
    
    const data = await response.json();
    const result = data.choices[0].message.content;
    
    console.log(`âœ… Section ${sectionIndex + 1}: ${estimateTokens(result)} tokens gerados`);
    return result;
  } catch (error) {
    console.error(`âŒ Error synthesizing section ${sectionIndex + 1}:`, error);
    throw error;
  }
};

// ============= NÃVEL 3: DOCUMENT CONSOLIDATION =============
const consolidateDocument = async (
  sectionSyntheses: string[],
  userMessage: string,
  fileName: string,
  totalPages: number,
  openAIApiKey: string
): Promise<ReadableStream> => {
  const targetOutputTokens = Math.floor(totalPages * TOKENS_PER_PAGE * TARGET_OUTPUT_RATIO);
  const targetPages = Math.floor(totalPages * TARGET_OUTPUT_RATIO);
  
  console.log(`ğŸ¯ ConsolidaÃ§Ã£o Final: ${totalPages} pÃ¡ginas â†’ ${targetPages} pÃ¡ginas (${targetOutputTokens} tokens)`);
  
  const prompt = `VocÃª Ã© um especialista em ANÃLISE DOCUMENTAL PROFUNDA E CONSOLIDAÃ‡ÃƒO FINAL.

ğŸ“– DOCUMENTO COMPLETO: "${fileName}" (${totalPages} pÃ¡ginas)

SÃNTESES DAS SEÃ‡Ã•ES:
${sectionSyntheses.map((synthesis, i) => `\n[SEÃ‡ÃƒO ${i+1}/${sectionSyntheses.length}]\n${synthesis}\n`).join('\n---\n')}

PERGUNTA/CONTEXTO DO USUÃRIO:
${userMessage}

ğŸ¯ MISSÃƒO: Crie uma ANÃLISE FINAL de ${targetOutputTokens} tokens (70% do original, â‰ˆ${targetPages} pÃ¡ginas) com:

1. ğŸŒ PANORAMA GERAL: VisÃ£o holÃ­stica, estrutura, objetivos
2. ğŸ“‹ CONTEÃšDO CONSOLIDADO: Todos os tÃ³picos com detalhes, conceitos, dados, exemplos
3. ğŸ”¬ ANÃLISE PROFUNDA: PadrÃµes globais, conexÃµes, insights, avaliaÃ§Ã£o crÃ­tica
4. ğŸ“Š DADOS ESTRUTURADOS: Tabelas, listas, estatÃ­sticas, referÃªncias
5. ğŸ¯ RESPOSTA DIRETA: Resposta Ã  pergunta do usuÃ¡rio, recomendaÃ§Ãµes
6. ğŸ’¡ INSIGHTS: Takeaways, implicaÃ§Ãµes, prÃ³ximos passos

âš ï¸ REGRAS:
- MANTENHA 70% do conteÃºdo (${targetPages} pÃ¡ginas)
- NÃƒO resuma excessivamente
- USE Markdown extensivamente
- PRESERVE fidelidade mÃ¡xima

ğŸ¯ Target: ${targetOutputTokens} tokens (${targetPages} pÃ¡ginas)`;

  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${openAIApiKey}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "gpt-4.1-2025-04-14",
      messages: [{ role: "user", content: prompt }],
      max_completion_tokens: Math.min(64000, targetOutputTokens),
      temperature: 0.2,
      stream: true,
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`Document consolidation failed: ${response.status} - ${errorText}`);
  }
  
  return response.body!;
};

// ============= PROCESSAMENTO PARALELO =============
const processChunksInParallel = async (
  chunks: string[],
  totalPages: number,
  openAIApiKey: string
): Promise<string[]> => {
  const batchSize = 5;
  const results: string[] = [];
  
  for (let i = 0; i < chunks.length; i += batchSize) {
    const batch = chunks.slice(i, Math.min(i + batchSize, chunks.length));
    console.log(`ğŸ“¦ Processando batch ${Math.floor(i/batchSize) + 1}/${Math.ceil(chunks.length/batchSize)}`);
    
    const batchPromises = batch.map((chunk, idx) => 
      analyzeChunk(chunk, i + idx, chunks.length, totalPages, openAIApiKey)
    );
    
    const batchResults = await Promise.allSettled(batchPromises);
    
    batchResults.forEach((result, idx) => {
      if (result.status === 'fulfilled') {
        results.push(result.value);
      } else {
        console.error(`âŒ Chunk ${i + idx + 1} falhou:`, result.reason);
        throw new Error(`Chunk processing failed: ${result.reason}`);
      }
    });
    
    // Rate limiting
    if (i + batchSize < chunks.length) {
      await delay(2000);
    }
  }
  
  return results;
};

// ============= AGRUPAMENTO EM SEÃ‡Ã•ES =============
const groupIntoSections = (chunkAnalyses: string[], totalPages: number): string[][] => {
  let sectionsCount: number;
  if (totalPages <= 50) sectionsCount = 1;
  else if (totalPages <= 100) sectionsCount = 3;
  else if (totalPages <= 200) sectionsCount = 5;
  else if (totalPages <= 500) sectionsCount = 8;
  else sectionsCount = 12;
  
  const chunksPerSection = Math.ceil(chunkAnalyses.length / sectionsCount);
  const sections: string[][] = [];
  
  for (let i = 0; i < chunkAnalyses.length; i += chunksPerSection) {
    sections.push(chunkAnalyses.slice(i, i + chunksPerSection));
  }
  
  console.log(`ğŸ“‚ Agrupados ${chunkAnalyses.length} chunks em ${sections.length} seÃ§Ãµes`);
  return sections;
};

// ============= SERVIDOR PRINCIPAL =============
serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { message, documentContent, pageCount, fileName } = await req.json();
    
    console.log(`ğŸš€ Hierarchical RAG ativado: ${fileName} (${pageCount} pÃ¡ginas)`);
    console.log(`ğŸ¯ Target output: ${Math.floor(pageCount * TARGET_OUTPUT_RATIO)} pÃ¡ginas (70% do original)`);
    
    const openAIApiKey = Deno.env.get("OPENAI_API_KEY");
    if (!openAIApiKey) throw new Error("OPENAI_API_KEY not configured");
    
    // NÃVEL 1: Chunk Analysis
    console.log("\nğŸ“Š NÃVEL 1: Chunk Analysis");
    const chunks = createAdaptiveChunks(documentContent, pageCount);
    const chunkAnalyses = await processChunksInParallel(chunks, pageCount, openAIApiKey);
    
    // NÃVEL 2: Section Synthesis
    console.log("\nğŸ§© NÃVEL 2: Section Synthesis");
    const sections = groupIntoSections(chunkAnalyses, pageCount);
    const sectionPromises = sections.map((section, idx) => 
      synthesizeSection(section, idx, sections.length, openAIApiKey)
    );
    const sectionSyntheses = await Promise.all(sectionPromises);
    
    // NÃVEL 3: Document Consolidation + Streaming
    console.log("\nğŸ¯ NÃVEL 3: Document Consolidation (streaming)");
    const finalStream = await consolidateDocument(
      sectionSyntheses,
      message,
      fileName,
      pageCount,
      openAIApiKey
    );
    
    return new Response(finalStream, {
      headers: {
        ...corsHeaders,
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        "Connection": "keep-alive",
      },
    });
    
  } catch (error: any) {
    console.error("âŒ Hierarchical RAG error:", error);
    return new Response(
      JSON.stringify({ error: error.message || "Processing failed" }),
      {
        status: 500,
        headers: { ...corsHeaders, "Content-Type": "application/json" },
      }
    );
  }
});
