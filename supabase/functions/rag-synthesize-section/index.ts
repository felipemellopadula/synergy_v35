import "https://deno.land/x/xhr@0.3.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { analyses, sectionIndex, totalSections } = await req.json();
    const openAIKey = Deno.env.get('OPENAI_API_KEY');

    console.log(`[RAG Section ${sectionIndex + 1}/${totalSections}] Sintetizando ${analyses.length} an√°lises`);

    const prompt = `Voc√™ √© um sintetizador especializado em INTEGRA√á√ÉO DE INFORMA√á√ïES.

SE√á√ÉO [${sectionIndex + 1} de ${totalSections}]

AN√ÅLISES DOS CHUNKS:
${analyses.join('\n\n---\n\n')}

üéØ MISS√ÉO: Crie uma s√≠ntese integrada que:
1. Una todas as an√°lises em narrativa coerente
2. Preserve TODOS os detalhes importantes
3. Elimine apenas redund√¢ncias exatas
4. Mantenha dados, exemplos e conceitos
5. Preserve terminologia t√©cnica

‚ö†Ô∏è PRESERVE 80% do conte√∫do das an√°lises
Use Markdown extensivamente`;

    // Retry logic
    const MAX_RETRIES = 2;
    let lastError;

    for (let attempt = 0; attempt <= MAX_RETRIES; attempt++) {
      try {
        const response = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Authorization": `Bearer ${openAIKey}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            model: "gpt-4.1-2025-04-14",
            messages: [{ role: "user", content: prompt }],
            max_completion_tokens: 16000,
            temperature: 0.2,
          }),
        });

        if (response.status === 429) {
          const retryAfter = response.headers.get('retry-after');
          const delay = retryAfter ? parseInt(retryAfter) * 1000 : 5000 * Math.pow(2, attempt);
          
          if (attempt < MAX_RETRIES) {
            console.log(`‚è≥ Section ${sectionIndex+1} rate limit, aguardando ${delay}ms...`);
            await new Promise(resolve => setTimeout(resolve, delay));
            continue;
          }
        }

        if (!response.ok) {
          lastError = await response.text();
          throw new Error(`OpenAI error: ${response.status}`);
        }

        const data = await response.json();
        const synthesis = data.choices[0].message.content;

        console.log(`[RAG Section ${sectionIndex + 1}/${totalSections}] ‚úÖ S√≠ntese conclu√≠da`);

        return new Response(
          JSON.stringify({ synthesis }),
          { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        );

      } catch (error) {
        lastError = error;
        if (attempt < MAX_RETRIES) {
          const delay = 3000 * Math.pow(2, attempt);
          console.log(`‚ö†Ô∏è Section ${sectionIndex+1} tentativa ${attempt+1} falhou, aguardando ${delay}ms...`);
          await new Promise(resolve => setTimeout(resolve, delay));
        }
      }
    }

    console.error(`[RAG Section ${sectionIndex + 1}] ‚ùå Falhou ap√≥s ${MAX_RETRIES+1} tentativas`);
    throw new Error(`Failed after ${MAX_RETRIES+1} attempts: ${lastError}`);


  } catch (error) {
    console.error('[RAG Section] Error:', error);
    return new Response(
      JSON.stringify({ error: error.message }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});
