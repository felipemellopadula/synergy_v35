import "https://deno.land/x/xhr@0.3.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Headers": "authorization, x-client-info, apikey, content-type",
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const { sections, userMessage, fileName, totalPages } = await req.json();
    const openAIKey = Deno.env.get('OPENAI_API_KEY');

    console.log(`[RAG Consolidate] Documento: "${fileName}" (${totalPages} pÃ¡ginas, ${sections.length} seÃ§Ãµes)`);
    
    // Log detalhado de cada seÃ§Ã£o recebida
    sections.forEach((section: string, idx: number) => {
      const sectionChars = section.length;
      const sectionTokens = Math.floor(sectionChars / 2.5);
      console.log(`  ðŸ“„ SeÃ§Ã£o ${idx + 1}: ${sectionChars} chars (~${sectionTokens} tokens)`);
      console.log(`  ðŸ“ Preview: ${section.substring(0, 80)}...`);
    });
    
    const totalCharsInSections = sections.reduce((sum: number, s: string) => sum + s.length, 0);
    console.log(`[RAG Consolidate] Total chars nas seÃ§Ãµes: ${totalCharsInSections} (~${Math.floor(totalCharsInSections / 2.5)} tokens)`);


    // Calcular output tokens primeiro
    const targetPages = Math.min(Math.floor(totalPages * 0.4), 30);
    const maxOutputTokens = Math.min(5000, Math.floor(targetPages * 80));
    
    // CALCULAR O PROMPT COMPLETO PRIMEIRO
    const promptTemplate = `Doc: "${fileName}" (${totalPages}p)

${sections.map((s: string, i: number) => `[${i+1}] ${s}`).join('\n\n')}

Q: ${userMessage}

Task: AnÃ¡lise ~${targetPages}p com visÃ£o geral, anÃ¡lise, insights, dados, resposta e conclusÃµes. Markdown.`;

    // VALIDAÃ‡ÃƒO com o prompt REAL
    const promptTokens = Math.floor(promptTemplate.length / 2.5);
    console.log(`[RAG Consolidate] Prompt total: ${promptTokens} tokens (${promptTemplate.length} chars)`);

    // HARD LIMIT baseado no prompt REAL (reduzido apÃ³s compressÃ£o obrigatÃ³ria)
    if (promptTokens > 10000) {
      console.error(`âŒ PROMPT MUITO GRANDE: ${promptTokens} tokens (limite: 10000)`);
      return new Response(
        JSON.stringify({ 
          error: `Prompt muito grande: ${promptTokens} tokens. Reduza o conteÃºdo antes de enviar.` 
        }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    const totalEstimatedTokens = promptTokens + maxOutputTokens;
    console.log(`[RAG Consolidate] Total estimado: ${totalEstimatedTokens} tokens (prompt: ${promptTokens}, output: ${maxOutputTokens})`);

    if (totalEstimatedTokens > 15000) {
      console.error(`âŒ TOTAL EXCEDE LIMITE: ${totalEstimatedTokens} tokens`);
      return new Response(
        JSON.stringify({ 
          error: `Total de tokens excede limite: ${totalEstimatedTokens}` 
        }),
        { status: 400, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    console.log(`[RAG Consolidate] âœ… ValidaÃ§Ã£o OK, chamando OpenAI (gpt-4.1, max_completion_tokens: ${maxOutputTokens})`);

    const prompt = promptTemplate;


    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${openAIKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-4.1-2025-04-14",
        messages: [{ role: "user", content: prompt }],
        max_completion_tokens: maxOutputTokens,
        stream: true,
      }),
    });

    if (!response.ok) {
      const error = await response.text();
      console.error('[RAG Consolidate] OpenAI error:', response.status, error);
      throw new Error(`OpenAI error: ${response.status} - ${error}`);
    }

    console.log('[RAG Consolidate] âœ… Streaming iniciado');

    // Stream da resposta
    const stream = new ReadableStream({
      async start(controller) {
        const reader = response.body!.getReader();
        const decoder = new TextDecoder();
        
        try {
          while (true) {
            const { done, value } = await reader.read();
            if (done) break;
            
            const chunk = decoder.decode(value);
            const lines = chunk.split('\n').filter(l => l.trim());
            
            for (const line of lines) {
              if (line.startsWith('data: ')) {
                controller.enqueue(new TextEncoder().encode(line + '\n\n'));
              }
            }
          }
          
          controller.enqueue(new TextEncoder().encode('data: [DONE]\n\n'));
          controller.close();
          console.log('[RAG Consolidate] âœ… Stream concluÃ­do');
        } catch (error) {
          console.error('[RAG Consolidate] Stream error:', error);
          controller.error(error);
        }
      }
    });

    return new Response(stream, {
      headers: {
        ...corsHeaders,
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
      }
    });

  } catch (error) {
    console.error('[RAG Consolidate] Error:', error);
    return new Response(
      JSON.stringify({ error: error.message }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );
  }
});
